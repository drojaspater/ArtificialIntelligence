{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c0b26e9",
   "metadata": {},
   "source": [
    "# Notas de Inteligencia Artificial \n",
    "Estas notas se realizan con respecto a lo enseñado por el profesor Alvaro Mauricio Montenegro Diaz y con respecto a sus notas de clase del curso del **Inteligencia Artificial** de la Universidad Nacional de Colombia. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c51e3b",
   "metadata": {},
   "source": [
    "## Redes Neuronales\n",
    "Como tal, las redes neuronals buscan simular el funcionamiento de las redes biologicas en los organismos vivos, por esto es importante que recordemos algunas de las caracteristicas de las neuronas biologicas segun los biologos:\n",
    "* **Función de la Dendrita.** Recibe las señales de otras neuronas.\n",
    "* **Soma (cuerpo celular).** Suma todas las señales entrantes para generar una señal total de entrada(input).\n",
    "* **Estructura del Axón.** Cuando la suma sobrepasa un cierto umbral numérico, la neurona se activa, dispara y la señal viaja a través del axón hacia otras neuronas.\n",
    "* **Trabajo de la Sinápsis.** Es el punto donde se realiza la interconexión de una neurona con otras neuronas. La cantidad de la señal transmitida depende en la fuerza (peso sináptico) de las conexiones. Las conexiones pueden ser inhibidoras (disminuyendo la fuerza) o de excitación (aumentando la fuerza) en principio.\n",
    "\n",
    "Estas acciones podemos asociarlas a una transformación de ciertos parametros, donde hay una información de llegada por medio de las dendritas, luego es transformada y sumada en el cuerpo celular, para ser transmitada mediante una información de salida por medio del axón, siendo la sinápsis la forma en que se comparten información las neuronas. Así es como funciona una red neuronal simple, tal que:\n",
    "* Las dendritas in las Redes Neuronales Biológicas son un análogo a las entradas conteniendo un peso especifico basada en la interconexión \"sináptica\" presente en la Red Neuronal Artificial.\n",
    "* El cuerpo celular es comparable a la unidad artificial llamada \"neurona\" en una Red Neuronal Artificial, que también comprende la suma de señales y umbral de activación.\n",
    "* La salida de los Axones (presentes en la sinápsis) son el análogo de los datos de salida en la Red Neuronal Artificial.\n",
    "\n",
    "Para empezar a trabajar con redes, es importante tener en claro que trabajar con una sola neurona limita las capacidades de nuestra red. Por este motivo, se suelen utilizar multiples neuronas por capas como se muestra acontinuación.\n",
    "\n",
    "![Esquema de positron con multiples capas ocultas](https://iapunk.es/wp-content/uploads/2022/11/matias-alvarado.png)\n",
    "\n",
    "Hay tres partes normalmente en una red neuronal : una capa de entrada, con unidades que representan los campos de entrada; una o varias capas ocultas; y una capa de salida, con una unidad o unidades que representa el campo o los campos de destino. Las unidades se conectan con fuerzas de conexión variables (o ponderaciones). Los datos de entrada se presentan en la primera capa, y los valores se propagan desde cada neurona hasta cada neurona de la capa siguiente. al final, se envía un resultado desde la capa de salida.\n",
    "\n",
    "Podemos entonces ver las redes neuronales como mapeos a los que le hacemos entrar una información inicial y nos devuelven un resultado final. El teorema de representación universal \"The Universal Approximation Theorem\n",
    "\" nos garantiza que cualquier función $Y=Y(x)$ puede ser representada por una red, incluso para mapeos complejos.\n",
    "\n",
    "La red neuronal más conocida es el **perceptron**, un tipo de red que conciste en distintas neuronas que realizan regresiones de los datos variando ciertos parametros que deben ser maximizados por medio de  algun metodo maximal como lo es el del gradiente descendiente y un metodo de comparación mediante una función de activación que nos permite saber cuando tendremos el valor deseado por la red. En general se trata de un algoritmo para el aprendizaje supervisado de clasificadores binarios.\n",
    "\n",
    "Sin embargo, el perceptron no es la unica red neuronal existente, mayor mente conocido como arquitectura. Podemos clasificar las arquitecturas de redes neuronales en 5 primordiales:\n",
    "\n",
    "1. **Red neuronal de perceptrón multicapa.** Estas redes utilizan más de una capa oculta de neuronas, a diferencia del perceptrón de una sola capa. También se conocen como Redes neuronales de alimentación profunda.\n",
    "\n",
    "2. **RNA convolucional.** Esta redes se basan en el concepto matemáticos de convolución. Escencialmente se basan en filtros que se aplican por ejemplo a las imágenes. Los filtros son estimados para cada red.\n",
    "\n",
    "3. **Transformer.** Estas redes sons especiales para el tratamiento de procesamiento de lenguaje natural. Recientemente han sido aplicadas a series de tiempo e imágenes. Se basan en el concepto de auto-atención.\n",
    "\n",
    "4. **Red neuronal recurrente.** Tipo de red neuronal en la que las neuronas de cada capa oculta tienen auto-conexiones. Las redes neuronales recurrentes poseen memoria. En cualquier caso, la neurona de capa oculta recibe la activación de la siguiente capa, así como su valor de activación anterior. Muy usadas principalemnte en series de tiempo. Los modelos más conocidos con LSTM y GRU.\n",
    "\n",
    "5. **Red autocodificadora o auto-encoder.** Es escencialmente un perceptron multicapa de múltiples usos como parte de otras arquitecturas. Por sí mismas son útiles para hacer reducción de dimensión de los datos.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c4a0ba",
   "metadata": {},
   "source": [
    "## Enfoque Matemático de una RNA\n",
    "Ahora tratemos de entender mejor como funciona una red neuronal. Cómo meniconamos incialmente, la red neuronal recibe información incialemte en su capa de entrada, por medio de un vector de información $x=(x_1,\\ldots,x_n)$, de modo que la capa de entrada tendra $n$ neuronas artificales.\n",
    "\n",
    "Cada componente $x_i$ de la capa de entrada se multiplica por el peso correspondiente $w_i$, donde los pesos son la información utilizada por la red neuronal para resolver un problema específico. Estos pesos deben aprenderse (ajustarse, estimarse) en el paso de entrenamiento, como se menciono anteriormente poara el perceptron. Los pesos representan el conocimiento que tiene lared del problema en cuestión. \n",
    "\n",
    "Ahora, los pesos y la formación de entrada deben ser combiandos mediante un producto escalar, de modo que la información de salida sera una combinación lineal de la información transformada por el perceptron, y se agrefa un **sesgo** o **bias** que ayuda a acomadar los datos y el cual tambien puede ser variado en caso de ser requerido. \n",
    "\n",
    "La suma es entonces un número real $z=\\sum_i x_iw_i+b$ esta suma se transforma a través de una **función de activación**, digamos $g()$, para obtener la salida neta $x'=g(z)$. La función de activación determina el comportamiento de la neurona. La siguiente figura muestra como funciona lo anterior para una red con capas ocultas.\n",
    "\n",
    "![Funcionamiento de redes neuronales con capas ocultas](https://raw.githubusercontent.com/AprendizajeProfundo/Diplomado-Avanzado/c01c908a0388a58b45cac707cb716438197a2d88/Redes%20Neuronales/Imagenes/ANN_Capa_Oculta.png)\n",
    "\n",
    "Note entonces, que en general los datos que entran antes de aplicar la función de activación son transformaciones afines de los datos de entrada, de modo que si utilizamos multiples neuronas con solo esta información de saldia, solo podremos replicar comportamientos lineales, por lo que la función de activación permite realizar tareas más complejas. \n",
    "\n",
    "##Optimización \n",
    "Para que la red neuroal funcione, nuetra tarea es hacer que los parametros de la red se ajusten a los parametros del modelo utilizando los datos de entrada, de tal manera que esto lo realice la propia red neuronal de manera supervisada. Para esto, definimos lo que se conoce como una **función de costo** o **función de pérdida**, la acual se encarga de estimar la precisión del perceptron con respecto al objetivo. Por lo que lo unico que falta por hacer es minimizar la función de costo con el objetivo de encontrar los parametros que minimizan el error.\n",
    "\n",
    "La función de costo puede tener multiples formas dependiendo del problema que estemos tratando, como podria ser el primer momento (valor esperado) o el segundo momento (variancia), dependiendo del tipo de problema de optimización que nos encontremos. Esto nos conduce a un nuevo problema, el cual consiste en como calcular los gradientes descendientes de la función de costo sabiendo que estos apunten en la dirección en que se encuentran los minimos locales o globales de la misma, siendo imposible saber en cual de estos nos encontramos. \n",
    "\n",
    "## Métodos de optimización basados en el gradiente\n",
    "Entonces, en resumen, el problema de aprendizaje se reduce a un problema de optimización. El metodo general del **gradiente descendiente**, implica utilizar $-\\nabla_x f(x)$ para buscar minimos locales, de modo que el metodo se escribe como:\n",
    "\n",
    "$$ x^{(k+1)} = x^{(k)} - \\eta_k \\nabla_x f(x^{(k)})  $$\n",
    "\n",
    "donde los valores $\\eta_k$ se suele llamar **tasa de aprendizaje** la cual se encarga de controlar el tamaño de paso de tal forma que logremos ubicarnos cerca del minimo local deseado.\n",
    "\n",
    "###  Gradiente descendiente en lote\n",
    "Este es un metodo que consiste en utilizar el metodo clasico vainilla pero con la diferencia de que se realiza la optimización por lotes, esto con el objetivo de reducir el esfuerzo computacional que requiere optmizar un conjunto de datos muy grande. De esta forma, si escogemos el conjunto de datos de entrenamiento $(\\mathbf{x}_{train},\\mathbf{y}_{train})$ y definimos a $\\mathfrak{L}$ como la función de pérdida, entonces obtendremos \n",
    "$$ \\mathbf{\\theta}_{k+1} = \\mathbf{\\theta}_{k}  -\\eta_k \\nabla_{\\mathbf{\\theta}}\\mathfrak{L}(\\mathbf{x}_{train},\\mathbf{y}_{train},\\mathbf{\\theta}_{k})$$\n",
    "donde $\\mathbf{\\theta}$ es el conjunto de datos de entrenamiento completo. El principal problema de resolver el gradiente descendiente es como encontrar la tasa de aprendizake $\\eta_k$ apropieda para el entrenamiento. note que la tasa de aprendizaje toma valores entre $0$ y $1$ siendo cero el caso extremo en que la neurona no se ajusta y uno el caso en que se hace una mayor variación de los parametros.\n",
    "### Gradiente descendiente estocástico\n",
    "Una variación del metodo de gradiente descendiente en lote es el  Gradiente descendiente estocástico, el cual cosnsiste en escoger los paramatros de entrenamiento $(\\mathbf{x}_{train},\\mathbf{y}_{train})$ seleccionadolos de manera al azar en cada época. \n",
    "\n",
    "Teniendo en cuenta los dos metodos anteriores, existen variaciones como lo puede ser el escoger mini-lotes que hacen de la optimización mucho más eficiente, sin embargo dos de los metodos más interesantes son el Método del momento y el metodo RMSprop.\n",
    "\n",
    "### Método del momento\n",
    "Los metodos del gradiente tienen complicaciónes en los puntos donde el gradiente cambia de forma abrupta tipica de los minimos locales, por esto el método del momento consiste en amortiguar las oscilaciones en torno al minimo local haciendo que el proceso de optimización se acelere, esto lo hace sumando una fracción $\\lambda$ del vector de actualización del paso anterior al vector de actualización actual. De forma que tenemos \n",
    "\n",
    "\\begin{align}\n",
    " \\mathbf{v}_{k} &= \\lambda  \\mathbf{v}_{k-1} + \\eta_k \\nabla_{\\mathbf{\\theta}}\\mathfrak{L}(\\mathbf{x}_{train},\\mathbf{y}_{train},\\mathbf{\\theta}_{k})\\\\\n",
    "\\mathbf{\\theta}_{k+1} &= \\mathbf{\\theta}_{k}  -  \\mathbf{v}_{k} \n",
    "\\end{align}\n",
    "donde $\\lambda<1$, usualemente igual a $0.9$.\n",
    "\n",
    "## RMSprop\n",
    "en este metodo dividimos la tasa de aprendizaje en cada caso por un promedio del cuadrado de los componente del gradiente del paso anterior. Por cada componente $\\theta$ del vector de parametros $\\mathbf{\\theta}$, sea $g$la respectiva componente del gradiente asociada a $\\theta$, entonces el métodos es como sigue:\n",
    "1. $E[g^2]_t=\\lambda E[g^2]_{t-1} + (1-\\lambda)g^2_t $\n",
    "2. $\\theta_{t-+1}=\\theta_t - \\frac{\\lambda}{\\sqrt{E[g^2]_{t+\\epsilon}}}g_t$\n",
    "\n",
    "donde el termino $\\epsilon>0$ ayuda a evitar diviones por cero.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f472a4a",
   "metadata": {},
   "source": [
    "## Teoría de la Información\n",
    "Las bases de la teoria de la información consisten en analizar la cantidad de información otorgada por un mensaje dependiendo del grado de sorpresa del mensaje. \n",
    "\n",
    "En general, si un evento tiene una probabilidad alta, entonces decimos que el evento **no es sorprendente**, por el contrario, eventos con baja probabilidad son eventos con un **alto grado de sorpresa**. Definido de una manera un poco más formal, decimos que el contenido de informacion  es la cantidad de información obtenida cuando se muestra una distribución de probabilidad, donde el contenido de información es una variable aleatoria definida para cualquier evento en la teoría de la probabilidad.\n",
    "\n",
    "En general, el valor esperado de la auto-información es lo que se conoce como **entropia**, la cual nos da información sobre la incertidumbre del ensamble estadistico, es decir, desde un punto de vista estadistico nos brinda la cinformación promedio de sun ensable y desde un punto de vista fisíco nos habla sobre el grado de \n",
    "desinformación del sistema. los ensambles con mayor incertidumbre son aquellos que asignan igual probabilidad para todo evento, es decir, distribuciónes de probabilidad constantes, mientras que la incertudumbre es cero solo si la distribución  de probabilidad es unitaria, es decir, conocemos el estado del sistema en su totalidad. \n",
    "\n",
    "Sea $X$ una variable aleatoria discreta con $\\Omega =\\{x_1,x_2,...\\}$ y probabilidades $\\mathcal{p}=\\{p_i|P(X=x_i), i=1,2,...\\}$. Si $x\\in\\Omega$, entonces el **contenido de información** o **información de shanon** del conjunto de eventos ${x}$ viede dado por:\n",
    "\n",
    "$$ I(\\{x\\}) = -\\log_kP(X=x)=\\log_k\\left[\\frac{1}{P(X=x)}\\right] $$\n",
    "\n",
    "donde $k$ es una base que depende de la cardinalidad de $\\Omega$, usualmente cuando trabajamos con datos que solo toman dos valores, tenemso k=2 y la unidad se denomina bit. Para logaritmos Neperianos utilizamos una unidad denominada nat.\n",
    "\n",
    "Por otra parte, la **entropía de Shannon** de la variable aleatoria $X$, o lo que es lo mismo, la entropía de la distribución asociada X se define como:\n",
    "$$ H(X)=\\sum_{x\\in\\Omega}P(X=z)I(x)= -\\sum_{x\\in\\Omega}P(X=z)\\log{P(x=x}=-\\sum_{i}p_i\\log{p_i}$$\n",
    "algunos autores llaman a esta cantidad incertidumbre, teniendo en cuenta la interpretación de la entropía. \n",
    "\n",
    "\n",
    "##La idea es buscar modelos lo menos entropicos posibles, es decir en los que tengamos total certesa de las predicciónes y por ende mayor predectibilidad. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f349ba",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
